from PyQt4.QtCore import *
from PyQt4.QtGui import *
import sys
import cv2 
import dlib
import numpy
from PIL import Image
from PyQt4 import QtGui
import time
import multiprocessing as mul
from multiprocessing import Process,Queue
from skimage import io

detector = dlib.get_frontal_face_detector()
sp = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
facerec = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")

MSG_QUEUE = Queue(10)
SHOW_QUEUE = Queue(1)
	
class MainWindow(QWidget):
    def __init__(self, msgQueue,shQueue,parent = None):
        QWidget.__init__(self)
	self.msg = msgQueue
	self.pip = shQueue
        self.resize(1000, 600)
        self.setWindowTitle('vedio control')
        self.image = QtGui.QPixmap()
       
        self.playcapture = cv2.VideoCapture("2.mp4")

        vbox = QVBoxLayout()

       
        self.piclabel = QLabel('pic')
	self.getlabel = QLabel('pic')
        hbox = QHBoxLayout()
	hbox.addWidget(self.piclabel)
        hbox.addStretch(1)
	hbox.addWidget(self.getlabel)

	self.title = QtGui.QLabel('Title')
	self.okButton = QtGui.QPushButton("OK")
	hbox1 = QHBoxLayout()
	hbox1.addWidget(self.title)
        hbox1.addStretch(1)
	hbox1.addWidget(self.okButton)

	vbox = QVBoxLayout()
	vbox.addLayout(hbox)
	vbox.addStretch(1)
	vbox.addLayout(hbox1)
	
	
       
        self.setLayout(vbox)
	self.sign = 0
	self.count = 0
       

        if self.image.load("chu.jpg"): 
            self.piclabel.setPixmap(self.image) 
	    self.getlabel.setPixmap(self.image) 

        self.playtimer = Timer("updatePlay()")
	self.playtimer.start()
	
       
        self.connect(self.playtimer, SIGNAL("updatePlay()"),
                                                    self.PlayVideo) 
        self.connect(self.okButton, SIGNAL("clicked()"),
                                              self.Thread_new)

	
    def Thread_new(self):
	self.sign = True


    def PlayVideo(self):
	
        ret,im = self.playcapture.read()
	if im is None:
		self.playcapture.release()
		self.playtimer.stop()
		return 
	img = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)
	img = cv2.resize(im,(640,360))
	height, width, bytesPerComponent = img.shape
	bytesPerLine = 3 * width
	cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)
	QImg = QImage(img.data, width, height, bytesPerLine,QImage.Format_RGB888)
	self.image = QImg
	self.piclabel.setPixmap(QPixmap.fromImage(self.image))

	if self.pip.empty() > 0:
		pass
	else:
		imgr = self.pip.get()
		height, width, bytesPerComponent = imgr.shape
		cv2.cvtColor(imgr, cv2.COLOR_BGR2RGB, imgr)
		QImgr = QImage(imgr.data, width, height, bytesPerLine,QImage.Format_RGB888)
		self.image = QImgr
		self.getlabel.setPixmap(QPixmap.fromImage(self.image))

	if self.sign == True:
		self.sign = False
		self.count = 10
	if self.count != 0:
		self.count -= 1
		self.msg.put(img)


           
   
class Timer(QThread):
   
    def __init__(self, signal = "updatePlay()", parent=None):
        super(Timer, self).__init__(parent)
        self.stoped = False
        self.signal = signal
        self.mutex = QMutex()


    def run(self):
        with QMutexLocker(self.mutex):
            self.stoped = False
        while True:
            if self.stoped:
                return

            self.emit(SIGNAL(self.signal))
            time.sleep(0.04)

    def stop(self):
        with QMutexLocker(self.mutex):
            self.stoped = True
        
    def isStoped(self):    
        with QMutexLocker(sellf.mutex):
            return self.stoped

def Show(msgQueue,shQueue):
	app = QApplication(sys.argv)
    	main = MainWindow(msgQueue,shQueue)
    	main.show()
    	sys.exit(app.exec_())


def Recgition(msgQueue,shQueue):  
        global detector,sp,facerec
        while 1:
      	   if msgQueue.qsize() != 10:
		pass
           else :
	      while msgQueue.qsize() != 0:
		img = msgQueue.get()		
    	        dets = detector(img, 1)	
	        if len(dets) == 2:
		   for i, d in enumerate(dets):
			
			shape = sp(img,d)
			face_descriptor = facerec.compute_face_descriptor(img, shape)
			if i == 0:
				v = numpy.array(face_descriptor)
				p1 = (d.left(), d.top())
				p2 = (d.right(), d.bottom())
			elif i == 1:
				w = numpy.array(face_descriptor)
				p3 = (d.left(), d.top())
				p4 = (d.right(), d.bottom())
				dist = numpy.linalg.norm(w-v)
				if dist > 0.56:
					print 'This is not ome person!\n'
				else:
					print 'This is one person!\n'
		cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)
		cv2.rectangle(img,p1,p2,(0,255,0),1)
		cv2.rectangle(img,p3,p4,(0,255,0),1)
		shQueue.put(img)

	




if __name__ == '__main__':
	processA = Process(target=Recgition,args=(MSG_QUEUE,SHOW_QUEUE,))
    	processB = Process(target=Show,args=(MSG_QUEUE,SHOW_QUEUE,))

    	processA.start()


    	processB.start()
	

    
