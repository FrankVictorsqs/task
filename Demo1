#coding:utf-8
from PyQt4.QtCore import *
from PyQt4.QtGui import *
import sys
import cv2 
import dlib
import numpy
from PIL import Image
from PyQt4 import QtGui
import time
import multiprocessing as mul
from multiprocessing import Process,Queue
from skimage import io

detector = dlib.get_frontal_face_detector()
sp = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
facerec = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")

MSG_QUEUE = Queue(10)
SHOW_QUEUE = Queue(1)
STATE_QUEUE = Queue(3)
	
class MainWindow(QWidget):
    def __init__(self, msgQueue,shQueue,state,parent = None):
        QWidget.__init__(self)
	self.msg = msgQueue
	self.pip = shQueue
	self.State = state
        self.resize(1000, 600)
        self.setWindowTitle('vedio control')
        self.image = QtGui.QPixmap()
       
        self.playcapture = cv2.VideoCapture("2.mp4")

        vbox = QVBoxLayout()

       
        self.piclabel = QLabel('pic')
	self.getlabel = QLabel('pic')
        hbox = QHBoxLayout()
	hbox.addWidget(self.piclabel)
        hbox.addStretch(1)
	hbox.addWidget(self.getlabel)

	self.state = QtGui.QLabel('Title')
	self.state.setFixedWidth(800)  
        self.state.setFixedHeight(100)  
        self.state.setAlignment(Qt.AlignCenter)  
	self.state.setFont(QFont("Roman times",30,QFont.Bold))
        self.state.setText(u"欢迎使用人、证票合一系统")
	self.okButton = QtGui.QPushButton("OK")
	hbox1 = QHBoxLayout()
        hbox1.addStretch(1)
	hbox1.addWidget(self.state)
        hbox1.addStretch(1)
	hbox1.addWidget(self.okButton)

	vbox = QVBoxLayout()
	vbox.addLayout(hbox)
	vbox.addLayout(hbox1)
	
	
       
        self.setLayout(vbox)
	self.sign = 0
	self.count = 0
	self.inter = 0
       

        if self.image.load("chu.jpg"): 
            self.piclabel.setPixmap(self.image) 
	    self.getlabel.setPixmap(self.image) 

        self.playtimer = Timer("updatePlay()")
	self.playtimer.start()
	
       
        self.connect(self.playtimer, SIGNAL("updatePlay()"),
                                                    self.PlayVideo) 
        self.connect(self.okButton, SIGNAL("clicked()"),
                                              self.Thread_new)

	
    def Thread_new(self):
	self.sign = True
	self.state.setText(u"开始人脸识别，正在捕捉人脸...")


    def PlayVideo(self):
	if self.State.empty() > 0:
		pass
	else : 
		self.state.setText(self.State.get())
        ret,im = self.playcapture.read()
	if im is None:
		self.playcapture.release()
		self.playtimer.stop()
		return 
	img = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)
	img = cv2.resize(im,(640,360))
	height, width, bytesPerComponent = img.shape
	bytesPerLine = 3 * width
	cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)
	QImg = QImage(img.data, width, height, bytesPerLine,QImage.Format_RGB888)
	self.image = QImg
	self.piclabel.setPixmap(QPixmap.fromImage(self.image))

	if self.pip.empty() > 0:
		pass
	else:
		imgr = self.pip.get()
		height, width, bytesPerComponent = imgr.shape
		cv2.cvtColor(imgr, cv2.COLOR_BGR2RGB, imgr)
		QImgr = QImage(imgr.data, width, height, bytesPerLine,QImage.Format_RGB888)
		self.image = QImgr
		self.getlabel.setPixmap(QPixmap.fromImage(self.image))

	if self.sign == True:
		self.getlabel.setPixmap(QPixmap.fromImage(self.image))
		self.sign = False
		self.count = 10
	
	if self.count != 0:
		if self.inter == 0:
			self.inter = 3
			self.count -= 1
			self.msg.put(img)
		else:
			self.inter -= 1


           
   
class Timer(QThread):
   
    def __init__(self, signal = "updatePlay()", parent=None):
        super(Timer, self).__init__(parent)
        self.stoped = False
        self.signal = signal
        self.mutex = QMutex()


    def run(self):
        with QMutexLocker(self.mutex):
            self.stoped = False
        while True:
            if self.stoped:
                return

            self.emit(SIGNAL(self.signal))
            time.sleep(0.04)

    def stop(self):
        with QMutexLocker(self.mutex):
            self.stoped = True
        
    def isStoped(self):    
        with QMutexLocker(sellf.mutex):
            return self.stoped

def Show(msgQueue,shQueue,state):
	app = QApplication(sys.argv)
    	main = MainWindow(msgQueue,shQueue,state)
    	main.show()
    	sys.exit(app.exec_())


def Recgition(msgQueue,shQueue,state):  
        global detector,sp,facerec,text
	
        while 1:
	   count = 0
	   place = []
	   rate = []
	   Max = 9
      	   if msgQueue.qsize() == 0:
		pass
           else :
	      while msgQueue.qsize() != 0:
			count += 1
			img = msgQueue.get()		
    	        	dets = detector(img, 1)	
	       	        if len(dets) == 2:
		   	    state.put(u"已捕捉到人脸和身份证照片，正在处理...")
		   	    for i, d in enumerate(dets):
				shape = sp(img,d)
				face_descriptor = facerec.compute_face_descriptor(img, shape)
				if i == 0:
					v = numpy.array(face_descriptor)
					p1 = (d.left(), d.top())
					p2 = (d.right(), d.bottom())
				elif i == 1:
					w = numpy.array(face_descriptor)
					p3 = (d.left(), d.top())
					p4 = (d.right(), d.bottom())
					dist = numpy.linalg.norm(w-v)
					place.append(dist)
					rate.append(Caculate(dist))
					if Caculate(dist) == 0:
						Max -= 2
					elif Caculate(dist) == 3:
						Max -= 2
					
							
		
			if count < Max:
				pass
			else:
				rate.sort()
				rate_c = len(rate)
				if rate_c > 5:
					x = 0
					for j in rate:
						if j == rate[0]
							pass
						elif j == rate[rate_c]
							pass
						else
							x += j
					x = x/(rate_c-2)
				
				else:
					x = 0
					for j in rate:
						x += j	
					
				for i in place:
						
				
				state.put(u"识别完成!您和身份证照片相似度为：99%!")
				while msgQueue.empty() > 0:
					msgQueue.get()	
				break
			cv2.cvtColor(img, cv2.COLOR_BGR2RGB, img)
			cv2.rectangle(img,p1,p2,(0,255,0),1)
			cv2.rectangle(img,p3,p4,(0,255,0),1)
			shQueue.put(img)


def Caculate(dist):
	if dist > 0.6:
		return 3
	elif dist > 0.5671:
		return 2
	elif dist > 0.5:
		return 1
	else:
		return 0	




if __name__ == '__main__':
	processA = Process(target=Recgition,args=(MSG_QUEUE,SHOW_QUEUE,STATE_QUEUE,))
    	processB = Process(target=Show,args=(MSG_QUEUE,SHOW_QUEUE,STATE_QUEUE,))

    	processA.start()


    	processB.start()
	

    
