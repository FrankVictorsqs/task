# coding=utf-8
import cv2
import dlib
import numpy


detector = dlib.get_frontal_face_detector()
sp = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")
facerec = dlib.face_recognition_model_v1("dlib_face_recognition_resnet_model_v1.dat")

win = dlib.image_window()


cap = cv2.VideoCapture('2.mp4')

j = 0
while cap.isOpened():

    ret, cv_img = cap.read()
    if cv_img is None:
        break

    j += 1
    if j == 30:
	break
    img = cv2.cvtColor(cv_img, cv2.COLOR_RGB2BGR)
    dets = detector(img, 0)
    display = []

    print("Number of faces detected: {}".format(len(dets)))

    if len(dets) == 2:
    	for i, d in enumerate(dets):
        	print("Detection {}: Left: {} Top: {} Right: {} Bottom: {}".format(
            		i, d.left(), d.top(), d.right(), d.bottom()))
		shape = sp(img,d)
		win.clear_overlay()
    		win.set_image(img)
    		win.add_overlay(dets)
		face_descriptor = facerec.compute_face_descriptor(img, shape)
		v = numpy.array(face_descriptor)
		display.append(v)
		if i == 1:
			w = numpy.array(face_descriptor)
			dis = []
			for k in display:
				dist = numpy.linalg.norm(k-w)
				dis.append(dist)
			print '\n The person is :',dis
	
    

cap.release()
